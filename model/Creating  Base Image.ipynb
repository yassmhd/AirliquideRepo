{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Scikit-Learn base Docker Image\n",
    "We will start our MLOps journey here by creating an abstract Docker Image for supporting Scikit-learn algorithms/models.\n",
    "\n",
    "\n",
    "So, after we create and test locally our Dockerfile, we'll send it to our first pipeline that will build this image and make it available in ECR.\n",
    "\n",
    "![Docker Diagram](../../imgs/DockerScikit_A.jpg)\n",
    "\n",
    "## First, lets create a Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM python:3.6-jessie\n",
    "\n",
    "RUN apt-get update -y && apt-get install -y libev-dev\n",
    "RUN pip install bottle bjoern opencv-python pandas numpy scipy scikit-learn\n",
    "\n",
    "RUN mkdir -p /opt/program\n",
    "RUN mkdir -p /opt/ml\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "ENV PATH=\"/opt/program:${PATH}\"\n",
    "\n",
    "COPY app.py /opt/program\n",
    "WORKDIR /opt/program\n",
    "\n",
    "EXPOSE 8080\n",
    "ENTRYPOINT [\"python\", \"app.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, the a basic application that will host our model code\n",
    "\n",
    "Please, notice that we're creating a WebService application with two methods: **ping** and **invocations**. Ping is for healthcheck and invocations is for calling your model.\n",
    "\n",
    "For a production environment it is important to use a **WSGI** solution. We will use a combo of **bottle** and **bjoern**. Bottle is our webservice api and bjoern our WSGI server. Since bjoern is single threaded, you can't run multiple predictions at the same time. If you need something like that, maybe you need gunicorn and a reverse proxy to protect your endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import bjoern\n",
    "import bottle\n",
    "\n",
    "from bottle import run, request, post, get\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# adds the model.py path to the list\n",
    "prefix = '/opt/ml'\n",
    "model_path = os.path.join(prefix, 'model')\n",
    "sys.path.insert(0,model_path)\n",
    "\n",
    "print(os.listdir(model_path))\n",
    "import model\n",
    "\n",
    "@get('/ping')\n",
    "def ping():\n",
    "    return \"\"\n",
    "\n",
    "@post('/invocations')\n",
    "def invoke():\n",
    "    # load image from POST and convert it to json\n",
    "    req = json.loads(request.body.read())\n",
    "    algo = request.get_header('X-Amzn-SageMaker-Custom-Attributes')\n",
    "    return json.dumps(model.predict(req, algo))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    if len(sys.argv) < 2 or ( not sys.argv[1] in [ \"serve\", \"train\", \"test\"] ):\n",
    "        raise Exception(\"Invalid argument: you must inform 'train' for training mode or 'serve' predicting mode\") \n",
    "\n",
    "    train = sys.argv[1] == \"train\"\n",
    "    test = sys.argv[1] == \"test\"\n",
    "    \n",
    "    if train:\n",
    "        model.train()\n",
    "\n",
    "    elif test:\n",
    "        algo = sys.argv[2]\n",
    "        req = eval(sys.argv[3])\n",
    "        print( model.predict(req, algo) )\n",
    "       \n",
    "    else:\n",
    "        bjoern.run(bottle.app(), \"0.0.0.0\", 8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Finally, let's create the buildspec\n",
    "This file will be used by CodeBuild for creating our base image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile buildspec.yml\n",
    "version: 0.2\n",
    "\n",
    "phases:\n",
    "  install:\n",
    "    runtime-versions:\n",
    "      docker: 18\n",
    "        \n",
    "  pre_build:\n",
    "    commands:\n",
    "      - echo Logging in to Amazon ECR...\n",
    "      - $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
    "  build:\n",
    "    commands:\n",
    "      - echo Build started on `date`\n",
    "      - echo Building the Docker image...\n",
    "      - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
    "      - docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "\n",
    "  post_build:\n",
    "    commands:\n",
    "      - echo Build completed on `date`\n",
    "      - echo Pushing the Docker image...\n",
    "      - echo docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - echo $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG > image.url\n",
    "      - echo Done!\n",
    "artifacts:\n",
    "  files:\n",
    "    - image.url\n",
    "  name: image_url\n",
    "  discard-paths: yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the image locally, first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sudo docker build -f Dockerfile -t base-image:latest ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we push our code to the repo, let's check the building process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sts_client = boto3.client(\"sts\")\n",
    "session = boto3.session.Session()\n",
    "\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = session.region_name\n",
    "credentials = session.get_credentials()\n",
    "credentials = credentials.get_frozen_credentials()\n",
    "\n",
    "repo_name='model'\n",
    "image_tag='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p tests\n",
    "!cp app.py Dockerfile buildspec.yml tests/\n",
    "with open('tests/vars.env', 'w') as f:\n",
    "    f.write(\"AWS_ACCOUNT_ID=%s\\n\" % account_id)\n",
    "    f.write(\"IMAGE_TAG=%s\\n\" % image_tag)\n",
    "    f.write(\"IMAGE_REPO_NAME=%s\\n\" % repo_name)\n",
    "    f.write(\"AWS_DEFAULT_REGION=%s\\n\" % region)\n",
    "    f.write(\"AWS_ACCESS_KEY_ID=%s\\n\" % credentials.access_key)\n",
    "    f.write(\"AWS_SECRET_ACCESS_KEY=%s\\n\" % credentials.secret_key)\n",
    "    f.write(\"AWS_SESSION_TOKEN=%s\\n\" % credentials.token )\n",
    "    f.close()\n",
    "\n",
    "!cat tests/vars.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "!/tmp/aws-codebuild/local_builds/codebuild_build.sh \\\n",
    "    -a \"$PWD/tests/output\" \\\n",
    "    -s \"$PWD/tests\" \\\n",
    "    -i \"samirsouza/aws-codebuild-standard:2.0\" \\\n",
    "    -e \"$PWD/tests/vars.env\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, now it's time to push everything to the correct repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ../../docker\n",
    "cp $OLDPWD/buildspec.yml $OLDPWD/app.py $OLDPWD/Dockerfile .\n",
    "\n",
    "git add --all\n",
    "git commit -a -m \" - build docker base image\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, now open the AWS console in another tab and go to the CodePipeline console to see the status of our building pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}